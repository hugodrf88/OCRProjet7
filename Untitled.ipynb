{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d027101d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evidently.model_profile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_preset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataDriftTestPreset\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_profile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Profile\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'evidently.model_profile'"
     ]
    }
   ],
   "source": [
    "#from evidently.dashboard import Dashboard\n",
    "#from evidently.tabs import DataDriftTab\n",
    "import evidently\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.model_profile import Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0063500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugo\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator FunctionTransformer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\hugo\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\hugo\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\hugo\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\hugo\\anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator FunctionTransformer from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\pickle.py:1489\u001b[0m, in \u001b[0;36m_Unpickler._instantiate\u001b[1;34m(self, klass, args)\u001b[0m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1489\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loaded_model\u001b[38;5;241m=\u001b[39m\u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/best_model.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../application_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m test\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../application_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pickle.py:1508\u001b[0m, in \u001b[0;36m_Unpickler.load_obj\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1506\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_mark()\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1508\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\pickle.py:1492\u001b[0m, in \u001b[0;36m_Unpickler._instantiate\u001b[1;34m(self, klass, args)\u001b[0m\n\u001b[0;32m   1489\u001b[0m         value \u001b[38;5;241m=\u001b[39m klass(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min constructor for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m-> 1492\u001b[0m                         (\u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m, \u001b[38;5;28mstr\u001b[39m(err)), sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m     value \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(klass)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_model=joblib.load(\"./models/best_model.pkl\")\n",
    "\n",
    "train=pd.read_csv(\"../application_train.csv\")\n",
    "test=pd.read_csv(\"../application_test.csv\")\n",
    "train=train.drop(\"SK_ID_CURR\",axis=1)\n",
    "test=test.drop(\"SK_ID_CURR\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f1a2b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evidently.model_profile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_preset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataDriftTestPreset\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_profile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Profile\n\u001b[0;32m     12\u001b[0m loaded_model\u001b[38;5;241m=\u001b[39mjoblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/best_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m train\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/application_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'evidently.model_profile'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X,y=train.drop(\"TARGET\",axis=1),train[\"TARGET\"]\n",
    "X_drift=test\n",
    "y_drift=loaded_model.predict(X_drift)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Créer un profil de modèle avec Evidently\n",
    "model_profile = Profile(model=loaded_model, \n",
    "                        data=X, \n",
    "                        target=y, \n",
    "                        task='classification')\n",
    "\n",
    "# Définir les paramètres de test de dérive de données\n",
    "data_drift_preset = DataDriftTestPreset()\n",
    "data_drift_preset.calculate(model_profile, X_drift, y_drift)\n",
    "\n",
    "# Créer un rapport Evidently\n",
    "data_drift_tab = DataDriftTab(test_result=data_drift_preset.test)\n",
    "sections = [data_drift_tab]\n",
    "dashboard = Dashboard(tabs=sections, title='Data Drift')\n",
    "report = dashboard.report()\n",
    "\n",
    "# Générer un tableau HTML\n",
    "report.save('drift_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9621669",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevidently\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_preset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryClassificationTestPreset\n\u001b[0;32m     19\u001b[0m label_binary_classification_performance \u001b[38;5;241m=\u001b[39m TestSuite(tests\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     20\u001b[0m     BinaryClassificationTestPreset(),\n\u001b[0;32m     21\u001b[0m ])\n\u001b[1;32m---> 23\u001b[0m label_binary_classification_performance\u001b[38;5;241m.\u001b[39mrun(reference_data\u001b[38;5;241m=\u001b[39m\u001b[43mloaded_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X), current_data\u001b[38;5;241m=\u001b[39mloaded_model\u001b[38;5;241m.\u001b[39mpredict(X_drift))\n\u001b[0;32m     24\u001b[0m label_binary_classification_performance\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, ensemble, model_selection\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.test_suite import TestSuite\n",
    "\n",
    "from evidently.test_preset import NoTargetPerformanceTestPreset\n",
    "from evidently.test_preset import DataQualityTestPreset\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.test_preset import RegressionTestPreset\n",
    "from evidently.test_preset import MulticlassClassificationTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTopKTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTestPreset\n",
    "\n",
    "\n",
    "label_binary_classification_performance = TestSuite(tests=[\n",
    "    BinaryClassificationTestPreset(),\n",
    "])\n",
    "\n",
    "label_binary_classification_performance.run(reference_data=loaded_model.predict(X), current_data=loaded_model.predict(X_drift))\n",
    "label_binary_classification_performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfbd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def fill_cat(df, most_frequent=False):\n",
    "    # Copie du DataFrame pour éviter toute modification de l'original\n",
    "    df_tmp = df.copy()\n",
    "    \n",
    "    # Sélection des colonnes catégorielles dans le DataFrame\n",
    "    # et stockage dans une liste\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "    # Remplissage des valeurs manquantes dans chaque colonne catégorielle\n",
    "    # en utilisant la stratégie \"most_frequent\" de SimpleImputer\n",
    "    if most_frequent: \n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        # Application de la méthode fit_transform de SimpleImputer \n",
    "        # pour remplacer les valeurs manquantes par la valeur la plus fréquente\n",
    "        df_tmp[cat_cols] = imputer.fit_transform(df_tmp[cat_cols])\n",
    "    # Sinon, remplir les valeurs manquantes dans chaque colonne catégorielle \n",
    "    # avec la chaîne \"Other\"\n",
    "    else:\n",
    "        df_tmp[cat_cols] = df_tmp[cat_cols].fillna(\"Other\")\n",
    "\n",
    "    # Retourne les valeurs du DataFrame rempli\n",
    "    return df_tmp.values\n",
    "\n",
    "\n",
    "def fill_num(df, strategy=\"median\"):\n",
    "    \"\"\"\n",
    "    Remplit les valeurs manquantes dans les colonnes numériques d'un DataFrame avec une stratégie donnée.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame contenant les colonnes numériques à remplir.\n",
    "        strategy (str): Stratégie à utiliser pour remplir les valeurs manquantes. Les options sont \"mean\",\n",
    "            \"median\", \"most_frequent\" et \"constant\". La valeur par défaut est \"median\".\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Un tableau NumPy contenant les colonnes numériques avec les valeurs manquantes remplies.\n",
    "\n",
    "    \"\"\"\n",
    "    # Copier le DataFrame d'entrée pour éviter de modifier l'original\n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    # Créer un objet SimpleImputer avec la stratégie spécifiée\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "\n",
    "    # Sélectionner les colonnes numériques dans le DataFrame\n",
    "    cols = [col for col in df.columns if df[col].dtype == \"float64\"]\n",
    "\n",
    "    # Remplacer les valeurs manquantes dans chaque colonne numérique\n",
    "    df_tmp[cols] = imputer.fit_transform(df_tmp[cols])\n",
    "\n",
    "    # Retourner les colonnes numériques avec les valeurs manquantes remplies sous forme de tableau NumPy\n",
    "    return df_tmp.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
